import express from 'express';
import { PrismaClient } from '@prisma/client';
import axios from 'axios';
import { chatLimiter } from '../middleware/rateLimiter';

const router = express.Router();
const prisma = new PrismaClient();

// Interface pour les messages de chat
interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

// Endpoint public : envoyer un message au chatbot de l'application
// POST /api/app-chat
router.post('/', chatLimiter, async (req: express.Request, res: express.Response) => {
  try {
    const { message, conversationHistory } = req.body;

    if (!message || !message.trim()) {
      return res.status(400).json({ message: 'Le message est requis' });
    }

    // V√©rifier que la cl√© API OpenAI est configur√©e
    const openaiApiKey = process.env.OPENAI_API_KEY;
    if (!openaiApiKey) {
      console.error('‚ùå OPENAI_API_KEY non configur√©e');
      return res.status(500).json({ 
        message: 'Le service de chat n\'est pas configur√©. Contactez l\'administrateur.',
        fallback: true
      });
    }

    // R√©cup√©rer la configuration du chatbot
    const config = await prisma.appChatbotConfig.findFirst();

    if (!config || !config.isActive) {
      return res.status(503).json({ 
        message: 'Le chatbot n\'est pas disponible pour le moment.',
        fallback: true
      });
    }

    if (!config.context || config.context.trim() === '') {
      return res.status(503).json({ 
        message: 'Le chatbot n\'est pas encore configur√©. Revenez bient√¥t !',
        fallback: true
      });
    }

    console.log(`üí¨ [APP-CHAT] Message re√ßu: "${message.trim().substring(0, 100)}"`);
    console.log(`üí¨ [APP-CHAT] Contexte admin: ${config.context.length} chars`);

    // Limiter le contexte pour √©viter de d√©passer les limites de tokens
    const maxContextLength = 60000;
    const truncatedContext = config.context.length > maxContextLength 
      ? config.context.substring(0, maxContextLength) + '\n\n[... contexte tronqu√© ...]'
      : config.context;

    // Construire les messages pour l'API OpenAI
    const systemPrompt = `Tu es l'assistant commercial de My Guide Digital, une plateforme de cr√©ation de livrets d'accueil digitaux pour les professionnels du tourisme (locations courtes dur√©es, h√¥tels, campings, conciergeries).

R√àGLES IMPORTANTES :
1. Tu dois r√©pondre en utilisant UNIQUEMENT les informations fournies dans le contexte ci-dessous. Ce sont les informations que l'administrateur de My Guide Digital a pr√©par√©es pour toi.
2. Sois professionnel, chaleureux et enthousiaste. Tu repr√©sentes la marque My Guide Digital.
3. Ton objectif principal est de donner envie au prospect de demander une d√©monstration de l'application.
4. R√©ponds dans la langue utilis√©e par le prospect.
5. Ne r√©v√®le JAMAIS que tu es un mod√®le d'IA. Pr√©sente-toi comme l'assistant My Guide Digital.
6. Si le prospect demande une d√©mo, guide-le vers la prise de contact (email, formulaire, etc.) selon les informations du contexte.
7. Utilise des emojis quand c'est appropri√© pour rendre la conversation plus conviviale.
8. Si tu ne connais pas la r√©ponse √† une question, oriente le prospect vers l'email de contact.

CONTEXTE ET INFORMATIONS DE MY GUIDE DIGITAL :
${truncatedContext}`;

    const messages: ChatMessage[] = [
      { role: 'system', content: systemPrompt }
    ];

    // Ajouter l'historique de conversation (limit√© aux 10 derniers messages)
    if (conversationHistory && Array.isArray(conversationHistory)) {
      const recentHistory = conversationHistory.slice(-10);
      for (const msg of recentHistory) {
        if (msg.role === 'user' || msg.role === 'assistant') {
          messages.push({
            role: msg.role,
            content: msg.content
          });
        }
      }
    }

    // Ajouter le message actuel de l'utilisateur
    messages.push({ role: 'user', content: message.trim() });

    // Appeler l'API OpenAI
    const openaiResponse = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
        messages,
        max_tokens: 1000,
        temperature: 0.7,
        top_p: 0.9,
      },
      {
        headers: {
          'Authorization': `Bearer ${openaiApiKey}`,
          'Content-Type': 'application/json',
        },
        timeout: 30000,
      }
    );

    const assistantMessage = openaiResponse.data.choices?.[0]?.message?.content;

    if (!assistantMessage) {
      console.error('‚ùå R√©ponse OpenAI invalide:', openaiResponse.data);
      return res.status(500).json({ 
        message: 'Erreur lors de la g√©n√©ration de la r√©ponse',
        fallback: true
      });
    }

    console.log(`üí¨ [APP-CHAT] R√©ponse g√©n√©r√©e (${openaiResponse.data.usage?.total_tokens} tokens)`);

    // Retourner la r√©ponse
    res.json({
      response: assistantMessage.trim(),
      usage: {
        promptTokens: openaiResponse.data.usage?.prompt_tokens,
        completionTokens: openaiResponse.data.usage?.completion_tokens,
        totalTokens: openaiResponse.data.usage?.total_tokens,
      }
    });

  } catch (error: any) {
    console.error('‚ùå App chat error:', error.response?.data || error.message);
    
    if (error.response?.status === 429) {
      return res.status(429).json({ 
        message: 'Trop de requ√™tes. Veuillez r√©essayer dans quelques instants.',
        fallback: true
      });
    }
    
    if (error.response?.status === 401) {
      return res.status(500).json({ 
        message: 'Erreur de configuration du service de chat.',
        fallback: true
      });
    }

    if (error.code === 'ECONNABORTED') {
      return res.status(504).json({ 
        message: 'Le service met trop de temps √† r√©pondre. Veuillez r√©essayer.',
        fallback: true
      });
    }

    res.status(500).json({ 
      message: error.message || 'Erreur lors du traitement du message',
      fallback: true
    });
  }
});

export default router;
